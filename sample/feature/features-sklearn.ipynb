{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  特征选择\n",
    "\n",
    "[结合Scikit-learn介绍几种常用的特征选择方法](http://blog.csdn.net/bryan__/article/details/51607215)\n",
    "\n",
    "[Feature selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n",
    "\n",
    "- [去掉取值变化小的特征](#id1)\n",
    "\n",
    "- [单变量特征选择](#id2)\n",
    "\n",
    "- [线性模型和正则化](#id3)\n",
    "\n",
    "- [随机森林](#id4)\n",
    "\n",
    "- [两种顶层特征选取](#id5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id1'>去掉取值变化小的特征</h2>\n",
    "\n",
    "如果一个特征中大部分数据都是同一个数,可以去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X = [[0,0,1],[0,1,0],[1,0,0],[0,1,1],[0,1,0],[0,1,1]]\n",
    "sel = VarianceThreshold(threshold=(.8*(1-0.8)))\n",
    "sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id2'>单变量特征选择</h2>\n",
    "\n",
    "- Pearson 相关系数\n",
    "\n",
    "用皮尔森相关系数衡量变量之间的线性相关性,取值区间 [-1,1];-1表示负相关,+1 表示正相关,0 表示没有线性相关\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86602540378443871, 0.33333333333333331)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "X = [1,2,3]\n",
    "y = [1,2,2]\n",
    "pearsonr(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id3'>基于学习模型的特征排序</h2>\n",
    "\n",
    "Pearson 相关系数评价的是否存在线性关系,对于非线性关系,可以用基于树(决策树,随机森林)或者扩展线性模型等.但需要注意过拟合问题,因此树的深度最好不要太大,再运用交叉验证.\n",
    "\n",
    "在[波士顿房价数据集](https://archive.ics.uci.edu/ml/datasets/Housing)上使用 sklearn 的[随机森林回归](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)给出一个单变量选择的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score,ShuffleSplit\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
       "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
       "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
       "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
       "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
       "       ..., \n",
       "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
       "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
       "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
       "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
       "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
       "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
       "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
       "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
       "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
       "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
       "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
       "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
       "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
       "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
       "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
       "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
       "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
       "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
       "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
       "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
       "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
       "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
       "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
       "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
       "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
       "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
       "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
       "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
       "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
       "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
       "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
       "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
       "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
       "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
       "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
       "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
       "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
       "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
       "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
       "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
       "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
       "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
       "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
       "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
       "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
       "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
       "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
       "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
       "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
       "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
       "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
       "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
       "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
       "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
       "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
       "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
       "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
       "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
       "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
       "        22. ,  11.9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], \n",
       "      dtype='|S7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.65, 'LSTAT'), (0.569, 'RM'), (0.415, 'INDUS'), (0.404, 'NOX'), (0.329, 'TAX'), (0.302, 'PTRATIO'), (0.208, 'CRIM'), (0.195, 'RAD'), (0.188, 'ZN'), (0.141, 'B'), (0.072, 'AGE'), (0.041, 'DIS'), (-0.028, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "X = boston['data']\n",
    "Y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20,max_depth=4)\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf,X[:,i:i+1],Y,scoring='r2',\n",
    "                           cv=ShuffleSplit(len(X),3,.3))\n",
    "    scores.append((round(np.mean(score),3),names[i]))\n",
    "print sorted(scores,reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id3'>线性模型和正则化<h2>\n",
    "\n",
    "越重要的特征在模型中系数会越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788],\n",
       "       [ 0.95008842, -0.15135721, -0.10321885],\n",
       "       ..., \n",
       "       [-0.74013679, -0.56549781,  0.47603138],\n",
       "       [-2.15806856,  1.31855102, -0.23929659],\n",
       "       [-0.24679356, -1.07934317, -0.11422555]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "size = 500\n",
    "\n",
    "# 3 个特征的数据集\n",
    "X = np.random.normal(0,1,(size,3))  # 数据集大小 size*3\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model: 1.975*X1 + 1.141*X0 + -0.061*X2\n"
     ]
    }
   ],
   "source": [
    "# Y = X0 + 2*X1 +noise\n",
    "Y = X[:,0] + 2*X[:,1] + np.random.normal(0,2,size) # size*1\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,Y)\n",
    "\n",
    "# 调整输出方式\n",
    "def pretty_print(coefs,names=None,sort=False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs,names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,key=lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s*%s\" % (round(coef,3),name) for coef,name in lst)\n",
    "\n",
    "print \"Linear model:\",pretty_print(lr.coef_,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41771335,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41526932, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41527165, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ..., \n",
       "       [-0.41137448, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40568883, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41292893, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston['data'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso mode1:  -3.707*LSTAT + 2.992*RM + -1.757*PTRATIO + -1.081*DIS + -0.7*NOX + 0.631*B + 0.54*CHAS + -0.236*CRIM + 0.081*ZN + -0.0*INDUS + -0.0*AGE + 0.0*RAD + -0.0*TAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/.local/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "Y = boston['target']\n",
    "names = boston['feature_names']\n",
    "\n",
    "# 如果继续增加alpha的值，得到的模型就会越来越稀疏，即越来越多的特征系数会变成0\n",
    "lasso = Lasso(alpha=.3)\n",
    "lasso.fit(X,Y)\n",
    "print \"Lasso mode1: \",pretty_print(lasso.coef_,names,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L2 正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0\n",
      "Linear model1: 0.728*X0 + 2.309*X1 + -0.082*X2\n",
      "Ridge model: 0.938*X0 + 1.059*X1 + 0.877*X2\n",
      "Random seed 1\n",
      "Linear model1: 1.152*X0 + 2.366*X1 + -0.599*X2\n",
      "Ridge model: 0.984*X0 + 1.068*X1 + 0.759*X2\n",
      "Random seed 2\n",
      "Linear model1: 0.697*X0 + 0.322*X1 + 2.086*X2\n",
      "Ridge model: 0.972*X0 + 0.943*X1 + 1.085*X2\n",
      "Random seed 3\n",
      "Linear model1: 0.287*X0 + 1.254*X1 + 1.491*X2\n",
      "Ridge model: 0.919*X0 + 1.005*X1 + 1.033*X2\n",
      "Random seed 4\n",
      "Linear model1: 0.187*X0 + 0.772*X1 + 2.189*X2\n",
      "Ridge model: 0.964*X0 + 0.982*X1 + 1.098*X2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "size = 100\n",
    "\n",
    "for i in range(5):\n",
    "    print \"Random seed %s\" %i\n",
    "    np.random.seed(seed=i)\n",
    "    X_seed = np.random.normal(0,1,size)\n",
    "    X1 = X_seed + np.random.normal(0,.1,size)\n",
    "    X2 = X_seed + np.random.normal(0,.1,size)\n",
    "    X3 = X_seed + np.random.normal(0,.1,size)\n",
    "    Y = X1 + X2 + X3 + np.random.normal(0,1,size)\n",
    "    X = np.array([X1,X2,X3]).T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,Y)\n",
    "    print \"Linear model1:\",pretty_print(lr.coef_)\n",
    "    \n",
    "    ridge = Ridge(alpha=10)\n",
    "    ridge.fit(X,Y)\n",
    "    print \"Ridge model:\",pretty_print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id4'>随机森林<h2>\n",
    "\n",
    "准确率高,鲁棒性好,易于使用\n",
    "\n",
    "下列中采用特征得分 Gini Importance,这种方法存在偏向,对具有更多类别的变量更加有利;2,对存在关联的多个特征,其中任意一个都可以作为指示器,一旦某个特征被选择之后,其他特征的重要性就会急剧下降 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.5027, 'LSTAT'), (0.3232, 'RM'), (0.0611, 'DIS'), (0.0249, 'NOX'), (0.0207, 'CRIM'), (0.0192, 'PTRATIO'), (0.0146, 'B'), (0.0133, 'TAX'), (0.0118, 'AGE'), (0.0057, 'INDUS'), (0.0015, 'RAD'), (0.0008, 'ZN'), (0.0006, 'CHAS')]\n"
     ]
    }
   ],
   "source": [
    "X = boston['data']\n",
    "Y = boston['target']\n",
    "names = boston['feature_names']\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    "print 'Features sorted by their score:'\n",
    "print sorted(zip(map(lambda x:round(x,4),rf.feature_importances_),names),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id='id5'>两种顶层特征选取<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 稳定性选择\n",
    "\n",
    "在不同的数据子集和特征子集上运行特征选择算法,不断重复,最终汇总特征选择结果.理想情况下,重要特征的得分会接近 100%,稍弱一点的特征得分会是接近0的数\n",
    "\n",
    "sklearn 中[随机lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLasso.html)和[随机逻辑回归](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RandomizedLogisticRegression.html)中有稳定性选择的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'RM'), (1.0, 'PTRATIO'), (1.0, 'LSTAT'), (0.635, 'B'), (0.56, 'CHAS'), (0.42, 'CRIM'), (0.36, 'TAX'), (0.205, 'NOX'), (0.175, 'DIS'), (0.155, 'INDUS'), (0.07, 'ZN'), (0.045, 'RAD'), (0.03, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "#波士顿数据集\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "rlasso = RandomizedLasso(alpha=.025)\n",
    "rlasso.fit(X,Y)\n",
    "\n",
    "print 'Features sorted by their score:'\n",
    "print sorted(zip(map(lambda x:round(x,4),rlasso.scores_),names),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 递归特征消除\n",
    "\n",
    "反复构建模型,选好最好(或最差)的特征,把选出来的特征放到一边,在剩下的特征重复这个过程,直到所有特征都遍历完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1.0, 'NOX'), (2.0, 'RM'), (3.0, 'CHAS'), (4.0, 'PTRATIO'), (5.0, 'DIS'), (6.0, 'LSTAT'), (7.0, 'RAD'), (8.0, 'CRIM'), (9.0, 'INDUS'), (10.0, 'ZN'), (11.0, 'TAX'), (12.0, 'B'), (13.0, 'AGE')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr,n_features_to_select=1)\n",
    "rfe.fit(X,Y)\n",
    "\n",
    "print 'Features sorted by their rank:'\n",
    "print sorted(zip(map(lambda x:round(x,4),rfe.ranking_),names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
