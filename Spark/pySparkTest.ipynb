{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习 Spark 的 python api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/hadoop/spark-2.0.1-bin-hadoop2.7\"   #KeyError: 'SPARK_HOME'\n",
    "sc=SparkContext(appName='Test')\n",
    "\n",
    "\n",
    "#conf = (SparkConf().setMaster('local').setAppName('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list 转化为 RDD\n",
    "rdd = sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter 过滤操作\n",
    "filterRdd = rdd.filter(lambda x:x>=4)\n",
    "filterRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map 对 rdd 每一个元素进行操作\n",
    "mapRDD = rdd.map(lambda x:x*2)\n",
    "mapRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# union 操作,将两个 RDD 合并为一个 RDD\n",
    "unionRDD = mapRDD.union(rdd)\n",
    "unionRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4, 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  count 结果统计, take 收集部分元素 属于行动操作\n",
    "print unionRDD.count()\n",
    "unionRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'hi']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMap:对每个输入元素生成多个输出元素\n",
    "lines = sc.parallelize([\"hello world\",\"hi\"])\n",
    "words = lines.flatMap(lambda line:line.split(\" \"))\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = sc.parallelize([[1,2,3],[4,5,6]])\n",
    "xx.flatMap(lambda x:map(lambda y:y,x)).collect()  # map 对子元素 [1,2,3],[4,5,6] 进行操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tea', 'panda', 'monkey', 'coffee']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  伪集合操作\n",
    "rdd1 = sc.parallelize(['coffee','coffee','panda','monkey','tea'])\n",
    "rdd2 = sc.parallelize(['coffee','monkey','kitty'])\n",
    "rdd1.distinct().collect() # 生成只包含不同元素的新的 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee', 'coffee', 'panda', 'monkey', 'tea', 'coffee', 'monkey', 'kitty']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.union(rdd2).collect()  # 包含两个 RDD 所有元素,并不会去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee', 'monkey']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.intersection(rdd2).collect()  # 包含两个 RDD 都有的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tea', 'panda']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.subtract(rdd2).collect() # 存在第一个 RDD 中,而不在第二个 RDD 中的所有元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  行动操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.reduce(lambda x,y:x+y)  # 接受 RDD 两个元素类型数据并返回同一个类型的新元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.fold(0,lambda x,y:x+y)  # fold 与 reduce 一样,只是需要指定一个初始值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spark算子：RDD行动Action操作](http://lxw1234.com/archives/2015/07/394.htm)\n",
    "\n",
    "**aggregate()**先对每个分区调用第一个lambda reduce,合并,再调用第二个 reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sc.parallelize([1,2,3,4,5,6,7,8,9,10],2)\n",
    "p.aggregate((0),\n",
    "           (lambda x,y:x+y),\n",
    "           (lambda a,b:a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 10)\n"
     ]
    }
   ],
   "source": [
    "#  取平均值\n",
    "\n",
    "sumCount = p.aggregate((0,0),\n",
    "                      (lambda x,y:(x[0]+y,x[1]+1)),  # 第一个参数 x,是 aggregate 传入的参数;第二个参数 y 是 p 的元素,返回一个元组\n",
    "                      (lambda a,b:(a[0]+b[0],a[1]+b[1]))) # a,b 是每个分区返回的元组\n",
    "\n",
    "print sumCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 3: 1, 4: 1, 5: 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各元素在 RDD 中出现的次数\n",
    "rdd.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   键值对操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'hello world'), ('hi', 'hi')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  创建 pair RDD,把一个普通的 RDD 转为 pair RDD,调用 map() 返回键值对\n",
    "pairs = lines.map(lambda x:(x.split(\" \")[0],x)) # 以第一个单词为键创建一个 pair RDD\n",
    "pairs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 1), ('world', 1), ('hi', 1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.flatMap(lambda line:line.split(\" \")). \\   # 先把单词分出来\n",
    "             map(lambda x:(x,1)).collect()      # 统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 10)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  reduceByKey 合并具有相同键的值,也就是对相同的 key 进行 reduce\n",
    "rdd = sc.parallelize([(1,2),(3,4),(3,6)])\n",
    "rdd.reduceByKey(lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{(1,[2]),(3,[4,6])}\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupByKey 对具有相同键的值进行分组,对相同 key 进行 group\n",
    "rdd.groupByKey().collect()\n",
    "'''\n",
    "{(1,[2]),(3,[4,6])}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (3, 5), (3, 7)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对 pair RDD 每个值进行操作,函数不改变键\n",
    "rdd.mapValues(lambda x:x+1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 3), (1, 4), (1, 5), (3, 4), (3, 5)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatMapValues() 对每个值应用一个返回迭代器的函数,然后对返回的每个元素和对应原键生成一个键值对记录\n",
    "rdd.flatMapValues(lambda x:range(x,6)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 4), (3, 6)]\n",
      "[(3, 4), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "# filter 对第二个元素进行筛选\n",
    "print rdd.collect()\n",
    "result = rdd.filter(lambda x:x[1]>2)\n",
    "print result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  combineByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据分组,查看顾客所有订单;groupByKey() 使用 RDD 中的键来对数据进行分组\n",
    "# 对于一个由类型 K 的键和类型 V 的值组成的 RDD，所得到的结果 RDD 类型会是 [K, Iterable[V]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Pair RDD 的行动操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 4), (3, 6)]\n",
      "defaultdict(<type 'int'>, {1: 1, 3: 2})\n"
     ]
    }
   ],
   "source": [
    "print rdd.collect()\n",
    "print rdd.countByKey()  # 对每个键对应的元素分别计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  累加器和广播变量\n",
    "\n",
    "累加器:用来对信息进行聚合,提供了将工作节点的值聚合到驱动器程序中,调适时对作业执行过程中事件进行计算\n",
    "广播变量:用来高效分发较大的对象\n",
    "\n",
    "\n",
    "**累加器用法:**\n",
    "\n",
    "* 通过驱动器中调用 SparkContext.accumulator(initialValue) 方法,创建存有初始值的累加器\n",
    "\n",
    "* 驱动器程序可以调用累加器的 value 属性访问累加器的值\n",
    "\n",
    "累加器的容错性:对于在行动操作中使用的累加器,Spark 只会对每个任务对各累加器的修改应用一次,必须放在 foreach 行动中,而在转化操作中,不保证容错性\n",
    "\n",
    "\n",
    "##  基于分区操作\n",
    "Spark 提供基于分区的 map 和 foreach,让部分代码只对 RDD 每个分区运行一次;通过基于分区的操作,可以在每个分区内共享一个数据库连接池,来避免建立太多连接. mapPartitions 函数获得输入 RDD 的每个分区中元素迭代器,返回执行结果的迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processCallSigns(signs):\n",
    "    \"\"\"使用连接池查询呼号\"\"\"\n",
    "    # 创建一个连接池\n",
    "    http = urllib3.PoolManager()\n",
    "    # 与每条呼号记录相关联的URL\n",
    "    urls = map(lambda x: \"http://73s.com/qsos/%s.json\" % x, signs)\n",
    "    # 创建请求（ 非阻塞）\n",
    "    requests = map(lambda x: (x, http.request('GET', x)), urls)\n",
    "    # 获取结果\n",
    "    result = map(lambda x: (x[0], json.loads(x[1].data)), requests)\n",
    "    # 删除空的结果并返回\n",
    "    return filter(lambda x: x[1] is not None, result)\n",
    "\n",
    "def fetchCallSigns(input):\n",
    "    \"\"\"获取呼号\"\"\"\n",
    "    return input.mapPartitions(lambda callSigns : processCallSigns(callSigns)) # callSigns 作为一个迭代器输入,proccess执行一次\n",
    "\n",
    "contactsContactList = fetchCallSigns(validSigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n"
     ]
    }
   ],
   "source": [
    "#  求平均值的分区方法\n",
    "nums = sc.parallelize([1,2,3,4,5,6,7,8,9,10,11,12],3)\n",
    "def combineCtrs(c1, c2):\n",
    "    return (c1[0] + c2[0], c1[1] + c2[1])\n",
    "\n",
    "def partitionCtr(nums):\n",
    "    \"\"\"计算分区的sumCounter\"\"\"\n",
    "    sumCount = [0, 0]\n",
    "    for num in nums:\n",
    "        sumCount[0] += num\n",
    "        sumCount[1] += 1\n",
    "    return [sumCount]\n",
    "\n",
    "def fastAvg(nums):\n",
    "    \"\"\"计算平均值\"\"\"\n",
    "    sumCount = nums.mapPartitions(partitionCtr).reduce(combineCtrs)  # 返回一个迭代器,再进行 reduce\n",
    "    return sumCount[0] / float(sumCount[1])\n",
    "print fastAvg(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}